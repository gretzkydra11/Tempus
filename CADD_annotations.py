"""

Author: Denis Avey
Date: 04/11/19

This script will generate a tab-delimited text file containing various info
parsed from the Challenge_data.vcf file, and the ANNOTATED CADD output (instead of EXAC).

Note 1: For more information on CADD and how to generate the CADD output file used here, see CADD_instructions

Note 2: All below code was developed using Python 3.7.3

"""
import os, vcf, pandas as pd, numpy as np, subprocess, ast

# Define local path to read/write files
current_wd = os.getcwd()
print("working directory:",current_wd)


# Read in VCF file using PyVCF
vcf_rd = vcf.Reader(open(current_wd+"/Challenge_data.vcf", 'r'))
print("Parsing VCF file...")
### Loop through each row of the VCF file and store relevant information in pandas DataFrame:
temp_dict = {}
vcf_df = pd.DataFrame()
art_id = 0
for record in vcf_rd:
    temp_dict = {art_id:[record.CHROM,record.POS,record.REF,record.ALT,record.INFO['TYPE'],record.INFO['DPB'],
    record.INFO['DP'],record.INFO['RO'],record.INFO['AO']]}
    vcf_df = vcf_df.append(pd.DataFrame.from_dict(temp_dict,orient='index'))
    art_id+=1

columns = ['CHROM','POS','REF','ALT','Var_type','Seq_coverage','Read_depth','Ref_reads','Var_reads']
vcf_df.columns = columns
print("VCF file successfully parsed...")

# Expand series with multiple values per row to a new row, allowing direct comparison with CADD output
var_type_df = pd.DataFrame(vcf_df['Var_type'].tolist(), index=vcf_df.index).stack().reset_index(level=1, drop=False)
var_type_df = var_type_df.reset_index()
var_reads_df = pd.DataFrame(vcf_df['Var_reads'].tolist(), index=vcf_df.index).stack().reset_index(level=1, drop=False)
var_reads_df = var_reads_df.reset_index()
alt_allele_df = pd.DataFrame(vcf_df['ALT'].tolist(), index=vcf_df.index).stack().reset_index(level=1, drop=False)
alt_allele_df = alt_allele_df.reset_index()


""""
In addition to PHRED score, there are ~100 columns of info, and multiple rows per variant, based on the
putative consequence of mutation. In addition, a 'ConsScore' offers an additional metric by which to rank variants.

Here, I apply a similar strategy as used in 'master_script.py' to filter out less deleterious variants
at a given site, based on their lower ConsScore.
"""

# Annotated CADD file contains more useful information not available in EXAC...
cadd = pd.read_csv(current_wd+"/CADD_Output_Annotated.tsv", header=1, sep='\t')
cadd = cadd.sort_values(['#Chr','Pos'], ascending=[True,True])

"""
After expanding rows containing lists of variables, collapse back to a single DataFrame and combine with various CADD info
In this case, I made a subset of the cadd data, only selecting a few columns of particular interest
Conveniently, the annotated CADD output contains Gene Name info, specific consequence of variant, expected clinical outcome, etc.
"""
cadd_sub = cadd[['#Chr','Pos','Ref','Alt','GeneName','PHRED','ConsScore','AnnoType','Consequence','SIFTcat','PolyPhenCat','Dist2Mutation']]

# Next, we need to remove rows of loci for which there are multiple variants, keeping only the most deleterious
# I accomplished this using a for loop, and if/else to obtain a list of indices to remove from the dataframe...

temp_df = pd.DataFrame()
temp_df2 = pd.DataFrame()

for i in range(0, len(cadd_sub)-1):
    if cadd_sub['Pos'][i] == cadd_sub['Pos'][i+1]:                    # if multiple variants per loci
        temp_df = cadd_sub.loc[cadd_sub['Pos'] == cadd_sub['Pos'][i]] # create subset df of these rows
        most_deleterious = temp_df['ConsScore'].idxmax(axis=1)        # determine which variant has highest 'ConsScore'
        temp_df = temp_df.loc[temp_df.index != most_deleterious]      # delete all other rows
        temp_df2 = temp_df2.append(temp_df)                           # append to new df after each loop

# Drop indices (variants) from original dataframe that are not the most deleterious
filtered_df = cadd_sub.drop(temp_df2.index)
filtered_df = filtered_df.reset_index(drop=True)

# This returns a df of 7487 rows, more than what is generated by 'master_script.py' filtering on PHRED score,
# because the CADD output file contains different 'Pos' values for insertions and deletions from the same loci.
# This makes it more difficult to re-merge this data...

# A 'brute force' workaround involves a second round of filtering...
temp_df = pd.DataFrame()
temp_df3 = pd.DataFrame()
for i in range(0, len(filtered_df)-1):
    if filtered_df['Dist2Mutation'][i] == filtered_df['Dist2Mutation'][i+1]:    # I noticed that the Dist2Mutation value is identical for variants from the same loci
        if filtered_df['Pos'][i+1] - filtered_df['Pos'][i] < 5:
            filtered_df.loc[[i,(i+1)], ['Pos']] = filtered_df['Pos'][i]         # set positions that are within 5 bp to be the same
            temp_df = filtered_df.loc[filtered_df['Pos'] == filtered_df['Pos'][i]] # the downstream steps are the same as above
            most_deleterious = temp_df['ConsScore'].idxmax(axis=1)        # determine which variant has highest 'ConsScore'
            temp_df = temp_df.loc[temp_df.index != most_deleterious]      # delete all other rows
            temp_df3 = temp_df3.append(temp_df)                           # append to new df after each loop

# filtered_df.loc[[,(i+1)], ['Pos']] = filtered_df['Pos'][i]
filtered_df = cadd_sub.drop(temp_df2.index)
filtered_df = filtered_df.reset_index(drop=True)

filtered_df2 = filtered_df.drop(temp_df3.index)
filtered_df2 = filtered_df2.reset_index(drop=True)

# This returns a df of 7012 rows, now only 35 more than what is generated by 'master_script.py'
# Upon manual inspection...
filtered_df2.to_csv(current_wd+"/VCF_DF_CADD.txt", sep='\t')

"""
It's likely that further filtering would enable integration of these CADD Annotations
with the records in the VCF file. Alternatively, perhaps local (offline) CADD analyses
could be customized/optimized to avoid issues by assigning a unique index for each
original record/row in the VCF file.
"""
